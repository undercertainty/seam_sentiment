{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEaM free text sentiment visualiser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plots the data from a SEaM spreadsheet as a series of bar charts. Change the filename in the marked cell to input from a new spreadsheet, then run all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by selecting a file. (The widget seems to need you to click on `Open` before it actually starts properly.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipyfilechooser import FileChooser\n",
    "\n",
    "fc=FileChooser()\n",
    "display(fc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull in the data and import libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AFAIK, the data is in a standard format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by importing the necessary modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And stop pandas from curtailing the outputs so we can see the whole text cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's get a SEaM data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this line to read the seam file\n",
    "\n",
    "feedback_df=pd.read_excel(fc.selected, sheet_name=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the contents of the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "feedback_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's whittle down to the columns we actually want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback_df=(feedback_df\n",
    " \n",
    " .rename({'If you answered Disagree to any of the statements above, we would like to understand why so we can make improvements in the future':'improvements',\n",
    "          'Do you have any further comments about your teaching, assessment and learning on this module?':'teaching_assessment_learning',\n",
    "          'Do you have any other comments to add about your study experience on this module?':'study_experience'},\n",
    "         axis='columns')\n",
    "\n",
    "    .filter(['improvements', 'teaching_assessment_learning', 'study_experience'], axis='columns')\n",
    "\n",
    "    .dropna(axis='rows', how='all')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the sentences in the free text cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To split the input into separate sentences, use the NLTK library function `sent_tokenize`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the language model for sentence splitting\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if we can put all the sentences into a single DataFrame. Reasonably tidily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=[]\n",
    "\n",
    "ss=(feedback_df['improvements']\n",
    " \n",
    "     .dropna()\n",
    ")\n",
    "\n",
    "for idx in ss.index:\n",
    "    l.extend([{'response':idx, 'sentence_num':i, 'improvements':s} for (i, s)\n",
    "              in enumerate(sent_tokenize(ss[idx]))])\n",
    "\n",
    "df1=pd.DataFrame(l)\n",
    "# df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=[]\n",
    "\n",
    "ss=(feedback_df['teaching_assessment_learning']\n",
    " \n",
    "     .dropna()\n",
    ")\n",
    "\n",
    "for idx in ss.index:\n",
    "    l.extend([{'response':idx, 'sentence_num':i, 'teaching_assessment_learning':s} for (i, s)\n",
    "              in enumerate(sent_tokenize(ss[idx]))])\n",
    "\n",
    "df2=pd.DataFrame(l)\n",
    "# df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=[]\n",
    "\n",
    "ss=(feedback_df['study_experience']\n",
    " \n",
    "     .dropna()\n",
    ")\n",
    "\n",
    "for idx in ss.index:\n",
    "    l.extend([{'response':idx, 'sentence_num':i, 'study_experience':s} for (i, s)\n",
    "              in enumerate(sent_tokenize(ss[idx]))])\n",
    "\n",
    "df3=pd.DataFrame(l)\n",
    "# df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_comments_df=(pd\n",
    "                 \n",
    "                 .merge(df1, df2, how='outer')\n",
    "                 \n",
    "                 .merge(df3, how='outer')\n",
    "                )\n",
    "\n",
    "all_comments_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_comments_df=(all_comments_df\n",
    " \n",
    "                 .sort_values(['response', 'sentence_num'])\n",
    " \n",
    "                 .set_index(['response', 'sentence_num'])\n",
    ")\n",
    "\n",
    "all_comments_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply the sentiment analyser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the Vader sentiment analyser from NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the language model for sentiment analysis\n",
    "\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sia.polarity_scores(\"TM351 was the best module I have ever imagined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sia.polarity_scores(\"TM351 is the worst course I have studied in decades at the OU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `'compound'` key in the dictionary is the one we want: range from -1 to +1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising the responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can combine the power of *seaborn*, which generates nice graded palettes, with *pandas*'  styling methods for DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can use the palette:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_colour_map=sns.diverging_palette(10, 125, s=75, l=50,\n",
    "                                           n=12, center=\"light\", as_cmap=True)\n",
    "sentiment_colour_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then map the sentences in the DataFrame onto the `compound` values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def polarity_scores_check(txt):\n",
    "    '''Returns the result of polarity_scores, but with 0 for cases\n",
    "       raising an error (avoids throwing errors for NaNs and the\n",
    "       like).\n",
    "    '''\n",
    "    try:\n",
    "        return sia.polarity_scores(txt)['compound']\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "all_comments_df.applymap(polarity_scores_check)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, we can use the polarity scores DataFrame to colour the cells in the text DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_comments_df.style.background_gradient(cmap=sentiment_colour_map,\n",
    "                                         axis=None, vmin=-1, vmax=1,\n",
    "                                          gmap=all_comments_df.applymap(polarity_scores_check))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
